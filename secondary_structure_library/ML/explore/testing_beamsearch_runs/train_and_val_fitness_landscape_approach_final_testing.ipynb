{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76c40df-8dfc-48bf-8c0b-04117b4403b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43b94da-5939-447e-b93c-7242569f13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme = {'blue':'#2f788e', 'red':'#d15b4f', 'green':'#45b563', 'grey':'#8a8888'}\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6f1ddd-f3df-4a37-b6b0-5a94d7e7e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqDist(s1, s2):\n",
    "    return sum([1 if b1 != b2 else 0 for b1, b2 in zip(s1, s2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f738b850-c1ab-4cd7-8c92-3b5cb602f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutateSeq(S, mut):\n",
    "    pos, mut_base = mut           \n",
    "    \n",
    "    if pos >= len(S):\n",
    "        raise Exception(\"Position out of range\") \n",
    "    \n",
    "    if pos == 0:\n",
    "        return mut_base + S[1:]\n",
    "    elif pos == len(S)-1:\n",
    "        return S[:len(S)-1] + mut_base\n",
    "    else:\n",
    "        return S[:pos] + mut_base + S[pos+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15236d9-0787-4647-bf94-30368a11cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMutations(S, mut):\n",
    "    Sx1 = S\n",
    "    for i in range(0, len(mut[0])):\n",
    "        Sx2 = mutateSeq(Sx1, (mut[0][i], mut[1][1][i]))\n",
    "        Sx1 = Sx2\n",
    "    return Sx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00266b7e-ec4e-4d81-8268-394f35a791c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot1Encode(S):\n",
    "    encoded = []\n",
    "    dct_bases = {'A': [1, 0, 0, 0], 'T': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'C': [0, 0, 0, 1]}\n",
    "    for b in S:\n",
    "        encoded.extend(dct_bases[b])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6077ee-49d4-46f5-9d20-06b858d372c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BfsNode:\n",
    "    seq: str\n",
    "    cpm: int\n",
    "    depth: int\n",
    "    muts_from_start: int\n",
    "\n",
    "@dataclass\n",
    "class Mutant:\n",
    "    seq: str\n",
    "    mut: list\n",
    "    pred_cpm: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b80e162-d66a-4284-a677-44d74c5be2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutantToNode(M, N):\n",
    "    \n",
    "    M_depth = N.depth+1\n",
    "    M_muts_from_start = N.muts_from_start+len(M.mut[0])\n",
    "    \n",
    "    return BfsNode(seq=M.seq, cpm=M.pred_cpm, depth=M_depth, muts_from_start=M_muts_from_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb7f2867-d6dd-45dc-a800-1797ff3e0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamSearch(start_seq_seq, start_seq_cpm, mutations, model, beam_width, mode, max_depth, exploration_cpm_threshold, top_explored):\n",
    "\n",
    "    queue = deque([BfsNode(seq=start_seq_seq, cpm=start_seq_cpm, depth=0, muts_from_start=0)])\n",
    "    explored_sequences = []\n",
    "    \n",
    "    while len(queue):\n",
    "        \n",
    "        # Get next node\n",
    "        next_node = queue.popleft()\n",
    "        \n",
    "        # Make every possible mutation -- get mutant batch\n",
    "        mutants_batch = [Mutant(seq=makeMutations(next_node.seq, mut), mut=mut, pred_cpm=None) for mut in mutations if ''.join([next_node.seq[x] for x in mut[0]]) == mut[1][0]]\n",
    "\n",
    "        # Run mutants through the blacklist filter\n",
    "        mutants_batch = [m for m in mutants_batch if m.seq not in blacklist]\n",
    "        if len(mutants_batch) == 0:\n",
    "            continue\n",
    "\n",
    "        # Encode mutants\n",
    "        mutants_encoded = np.array([np.array(hot1Encode(m.seq)) for m in mutants_batch])\n",
    "\n",
    "        # Make predictions about mutants\n",
    "        if len(mutants_encoded) == 1:\n",
    "            mutants_encoded = mutants_encoded.reshape(1, -1)\n",
    "\n",
    "        if mode == 'directed':\n",
    "            predictions = model.predict(mutants_encoded)\n",
    "        elif mode == 'random':\n",
    "            predictions = np.random.rand(len(mutants_encoded))\n",
    "\n",
    "        # Assign the predicted cpms\n",
    "        for i in range(0, len(predictions)):\n",
    "            mutants_batch[i].pred_cpm = predictions[i]\n",
    "\n",
    "        # Convert mutants from mutant class to bfs node class and sort by cpm\n",
    "        mutants_batch = [mutantToNode(m, next_node) for m in mutants_batch]\n",
    "        mutants_batch = sorted(mutants_batch, key=lambda p: p.cpm, reverse=True)\n",
    "\n",
    "        for i, m in enumerate(mutants_batch):\n",
    "            if len(explored_sequences) < top_explored:\n",
    "                    explored_sequences.append(m)\n",
    "                \n",
    "            else:\n",
    "                if m.cpm > explored_sequences[-1].cpm:\n",
    "                    del explored_sequences[-1]\n",
    "                    explored_sequences.append(m)\n",
    "                    explored_sequences = sorted(explored_sequences, key=lambda p: p.cpm, reverse=True)                        \n",
    "\n",
    "            if (i < beam_width) and (m.depth <= max_depth):\n",
    "                queue.append(m)\n",
    "\n",
    "            blacklist.add(m.seq)\n",
    "        \n",
    "    return explored_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4d47a-8a43-43b3-835d-5d8b2beaf03a",
   "metadata": {},
   "source": [
    "---\n",
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1465d875-8f7f-471e-a3e9-53bd2d66fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_metrics = pd.DataFrame(columns=['sampling', 'precision', 'recall', 'search_space'])\n",
    "df_res_seqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3d5360a-bc37-48ff-a59c-0feb12d1e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv('/home/jardic/Documents/projects/jk/datasets/datasets_prepped/strc_km.csv', usecols=['varseq', 'cpm'])\n",
    "\n",
    "# Make helpers\n",
    "seq_2_cpm = {s : c for s, c in zip(df['varseq'], df['cpm'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "198e9e8d-431d-44ed-b09d-641f0bdc5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_params = {\n",
    "    'topN_start' : 1,\n",
    "    'beam_width' : 3,\n",
    "    'max_depth' : 5,\n",
    "    'top_explored' : 100,\n",
    "    'mode' : 'directed'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6464d69a-7f24-49fa-87c7-6de73d48bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the splits\n",
    "with open('../testing_splits/splits.pkl', mode='rb') as sf:\n",
    "    splits = pickle.load(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b363993e-b7da-4835-9a63-1272abaa8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the possible mutations\n",
    "with open('../prep/allowed_mutations_permuations.pkl', mode='rb') as mf:\n",
    "    mutations = pickle.load(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d918a4e0-8c2c-4a88-874f-6f8d567162c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sampling_i, sampling_value in enumerate([1, 0.1, 0.01, 0.001]):\n",
    "    \n",
    "    # Get the sampled df\n",
    "    # [1, 0.1, 0.01, 0.001] These are the sampling of the training data\n",
    "    df_tst, df_val, df_trn = df.loc[splits['tst']], df.loc[splits['val']], df.loc[splits['trn'][sampling_i]]\n",
    "    \n",
    "    # Load the trained model\n",
    "    with open('../testing_models/model_trained_final_trn' + str(sampling_i) + '.pkl', mode='rb') as mf:\n",
    "        model = pickle.load(mf)\n",
    "\n",
    "    # I'll be using the best training sequences as starting points so sorting the training dataframe\n",
    "    df_trn = df_trn.sort_values('cpm', ascending=False)\n",
    "    \n",
    "    # Run beamsearch\n",
    "    blacklist = set(df_trn['varseq'].tolist())\n",
    "    res_all = []\n",
    "    for i in range(0, beam_search_params['topN_start']):\n",
    "        res_start = beamSearch(df_trn.iloc[i]['varseq'], df_trn.iloc[i]['cpm'],\n",
    "                               mutations=mutations, \n",
    "                               model=model,\n",
    "                               mode=beam_search_params['mode'],\n",
    "                               beam_width=beam_search_params['beam_width'],\n",
    "                               max_depth=beam_search_params['max_depth'],\n",
    "                               top_explored=beam_search_params['top_explored'],\n",
    "                               exploration_cpm_threshold=df_trn.iloc[0]['cpm'])\n",
    "        \n",
    "        res_all.extend(res_start)\n",
    "    \n",
    "    df_res_all = pd.DataFrame([[r.seq, r.cpm, r.depth, r.muts_from_start] for r in res_all], columns=['varseq', 'predicted_cpm', 'depth', 'muts'])\n",
    "    df_res_all = df_res_all.head(100)\n",
    "\n",
    "    df_res_seqs.append(df_res_all)\n",
    "    \n",
    "    seqs_exp = set(df_res_all['varseq'].tolist())\n",
    "    seqs_tst = set(df_tst['varseq'].tolist())\n",
    "    \n",
    "    precision = len(seqs_exp.intersection(seqs_tst)) / len(seqs_exp)\n",
    "    #print('precision:', precision)\n",
    "    \n",
    "    recall = len(seqs_exp.intersection(seqs_tst)) / len(seqs_tst)\n",
    "    #print('recall:', recall)\n",
    "    \n",
    "    search_space_size = len(blacklist) - len(df_trn)\n",
    "    #print('search space size:', search_space_size)\n",
    "    \n",
    "    df_res_metrics.loc[len(df_res_metrics)] = [sampling_value, precision, recall, search_space_size]\n",
    "    df_res_seqs.append(df_res_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a7c5d4-3230-465a-9749-c1e318b26e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>search_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>8537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8874.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sampling  precision  recall  search_space\n",
       "0     1.000       0.77    0.77        3381.0\n",
       "1     0.100       0.69    0.69        8537.0\n",
       "2     0.010       0.41    0.41        9063.0\n",
       "3     0.001       0.02    0.02        8874.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a33d2b5-ca9c-4708-a241-94500132b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_directed.pkl', mode='wb') as rf:\n",
    "    pickle.dump([df_res_metrics, df_res_seqs], rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf055e5a-aaec-44cd-a02e-b7e4a3f3569a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
