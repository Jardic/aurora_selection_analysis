{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76c40df-8dfc-48bf-8c0b-04117b4403b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e6f1ddd-f3df-4a37-b6b0-5a94d7e7e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqDist(s1, s2):\n",
    "    return sum([1 if b1 != b2 else 0 for b1, b2 in zip(s1, s2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f738b850-c1ab-4cd7-8c92-3b5cb602f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutateSeq(S, mut):\n",
    "    pos, mut_base = mut           \n",
    "    \n",
    "    if pos >= len(S):\n",
    "        raise Exception(\"Position out of range\") \n",
    "    \n",
    "    if pos == 0:\n",
    "        return mut_base + S[1:]\n",
    "    elif pos == len(S)-1:\n",
    "        return S[:len(S)-1] + mut_base\n",
    "    else:\n",
    "        return S[:pos] + mut_base + S[pos+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15236d9-0787-4647-bf94-30368a11cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMutations(S, mut):\n",
    "    Sx1 = S\n",
    "    for i in range(0, len(mut[0])):\n",
    "        Sx2 = mutateSeq(Sx1, (mut[0][i], mut[1][1][i]))\n",
    "        Sx1 = Sx2\n",
    "    return Sx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00266b7e-ec4e-4d81-8268-394f35a791c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot1Encode(S):\n",
    "    encoded = []\n",
    "    dct_bases = {'A': [1, 0, 0, 0], 'T': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'C': [0, 0, 0, 1]}\n",
    "    for b in S:\n",
    "        encoded.extend(dct_bases[b])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6077ee-49d4-46f5-9d20-06b858d372c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BfsNode:\n",
    "    seq: str\n",
    "    cpm: int\n",
    "    depth: int\n",
    "    muts_from_start: int\n",
    "\n",
    "@dataclass\n",
    "class Mutant:\n",
    "    seq: str\n",
    "    mut: list\n",
    "    pred_cpm: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b80e162-d66a-4284-a677-44d74c5be2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutantToNode(M, N):\n",
    "    \n",
    "    M_depth = N.depth+1\n",
    "    M_muts_from_start = N.muts_from_start+len(M.mut[0])\n",
    "    \n",
    "    return BfsNode(seq=M.seq, cpm=M.pred_cpm, depth=M_depth, muts_from_start=M_muts_from_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7f2867-d6dd-45dc-a800-1797ff3e0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamSearch(start_seq_seq, start_seq_cpm, mutations, model, beam_width, mode, max_depth, exploration_cpm_threshold, top_explored):\n",
    "\n",
    "    queue = deque([BfsNode(seq=start_seq_seq, cpm=start_seq_cpm, depth=0, muts_from_start=0)])\n",
    "    explored_sequences = []\n",
    "    \n",
    "    while len(queue):\n",
    "        \n",
    "        # Get next node\n",
    "        next_node = queue.popleft()\n",
    "        \n",
    "        # Make every possible mutation -- get mutant batch\n",
    "        mutants_batch = [Mutant(seq=makeMutations(next_node.seq, mut), mut=mut, pred_cpm=None) for mut in mutations if ''.join([next_node.seq[x] for x in mut[0]]) == mut[1][0]]\n",
    "\n",
    "        # Run mutants through the blacklist filter\n",
    "        mutants_batch = [m for m in mutants_batch if m.seq not in blacklist]\n",
    "        if len(mutants_batch) == 0:\n",
    "            continue\n",
    "\n",
    "        # Encode mutants\n",
    "        mutants_encoded = np.array([np.array(hot1Encode(m.seq)) for m in mutants_batch])\n",
    "\n",
    "        # Make predictions about mutants\n",
    "        if len(mutants_encoded) == 1:\n",
    "            mutants_encoded = mutants_encoded.reshape(1, -1)\n",
    "\n",
    "        if mode == 'directed':\n",
    "            predictions = model.predict(mutants_encoded)\n",
    "        elif mode == 'random':\n",
    "            predictions = np.random.rand(len(mutants_encoded))\n",
    "\n",
    "        # Assign the predicted cpms\n",
    "        for i in range(0, len(predictions)):\n",
    "            mutants_batch[i].pred_cpm = predictions[i]\n",
    "\n",
    "        # Convert mutants from mutant class to bfs node class and sort by cpm\n",
    "        mutants_batch = [mutantToNode(m, next_node) for m in mutants_batch]\n",
    "        mutants_batch = sorted(mutants_batch, key=lambda p: p.cpm, reverse=True)\n",
    "\n",
    "        for i, m in enumerate(mutants_batch):\n",
    "            if len(explored_sequences) < top_explored:\n",
    "                    explored_sequences.append(m)\n",
    "                \n",
    "            else:\n",
    "                if m.cpm > explored_sequences[-1].cpm:\n",
    "                    del explored_sequences[-1]\n",
    "                    explored_sequences.append(m)\n",
    "                    explored_sequences = sorted(explored_sequences, key=lambda p: p.cpm, reverse=True)                        \n",
    "\n",
    "            if (i < beam_width) and (m.depth <= max_depth):\n",
    "                queue.append(m)\n",
    "\n",
    "            blacklist.add(m.seq)\n",
    "        \n",
    "    return explored_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4d47a-8a43-43b3-835d-5d8b2beaf03a",
   "metadata": {},
   "source": [
    "---\n",
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65f0251-67d7-4900-94e8-d6247c5db3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv('/home/jardic/Documents/projects/jk/datasets/datasets_prepped/strc_km.csv', usecols=['varseq', 'cpm'])\n",
    "\n",
    "# Load the splits\n",
    "with open('../splits/splits.pkl', mode='rb') as sf:\n",
    "    splits = pickle.load(sf)\n",
    "\n",
    "# Load the possible mutations\n",
    "with open('../prep/allowed_mutations_permuations.pkl', mode='rb') as mf:\n",
    "    mutations = pickle.load(mf)\n",
    "\n",
    "# Load the hyperparameter combinations (hyperparameter grid)\n",
    "with open('../prep/mlp_hyperparameters.pkl', mode='rb')as hpc_f:\n",
    "    hpcs_all = pickle.load(hpc_f)\n",
    "\n",
    "# Get the sampled dfs\n",
    "# [1, 0.1, 0.01, 0.001] These are the sampling of the training data\n",
    "df_tst, df_val, df_trn = df.loc[splits['tst']], df.loc[splits['val']], df.loc[splits['trn'][2]]\n",
    "\n",
    "# I'll be using the best training sequences as starting points\n",
    "df_trn = df_trn.sort_values('cpm', ascending=False)\n",
    "\n",
    "# Make helpers\n",
    "seq_2_cpm = {s : c for s, c in zip(df['varseq'], df['cpm'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88627a2b-b15d-49da-b8da-d08b660ea400",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5553c6c7-1bb7-48d6-a469-c52e9005f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_params = {\n",
    "    'topN_start' : 5,\n",
    "    'beam_width' : 5,\n",
    "    'max_depth' : 5,\n",
    "    'top_explored' : 100,\n",
    "    'mode' : 'directed'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ac502e0-abd6-404d-985e-6640ce7df9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['hpc_index', 'hidden_layer_sizes', 'learning_rate_init', 'batch_size', 'precision', 'recall', 'search_space'])\n",
    "\n",
    "for hpc_index, hpc in hpcs_all:\n",
    "\n",
    "    # Load one of the trained models\n",
    "    model_file = '../hpc_tuning_models/model_trained_0p01_hpc_' + str(hpc_index) + '.pkl'\n",
    "    with open(model_file, mode='rb') as mf:\n",
    "        model = pickle.load(mf)\n",
    "\n",
    "    # Run beam search\n",
    "    blacklist = set(df_trn['varseq'].tolist())\n",
    "    res_all = []\n",
    "    for i in range(0, beam_search_params['topN_start']):\n",
    "        res_start = beamSearch(df_trn.iloc[i]['varseq'], df_trn.iloc[i]['cpm'],\n",
    "                               mutations=mutations, \n",
    "                               model=model,\n",
    "                               mode=beam_search_params['mode'],\n",
    "                               beam_width=beam_search_params['beam_width'],\n",
    "                               max_depth=beam_search_params['max_depth'],\n",
    "                               top_explored=beam_search_params['top_explored'],\n",
    "                               exploration_cpm_threshold=df_trn.iloc[0]['cpm'])\n",
    "        \n",
    "        res_all.extend(res_start)\n",
    "    \n",
    "    df_res_all = pd.DataFrame([[r.seq, r.cpm, r.depth, r.muts_from_start] for r in res_all], columns=['varseq', 'predicted_cpm', 'depth', 'muts'])\n",
    "    df_res_all = df_res_all.head(100)\n",
    "    \n",
    "    seqs_exp = set(df_res_all['varseq'].tolist())\n",
    "    seqs_val = set(df_val['varseq'].tolist())\n",
    "    seqs_tst = set(df_tst['varseq'].tolist())\n",
    "    \n",
    "    seqs_exp = seqs_exp - seqs_tst\n",
    "    \n",
    "    precision = len(seqs_exp.intersection(seqs_val)) / len(seqs_exp)\n",
    "    #print('precision:', precision)\n",
    "    \n",
    "    recall = len(seqs_exp.intersection(seqs_val)) / len(seqs_val)\n",
    "    #print('recall:', recall)\n",
    "    \n",
    "    search_space_size = len(blacklist) - len(df_trn)\n",
    "    #print('search space size:', search_space_size)\n",
    "    \n",
    "    df_results.loc[len(df_results)] = [hpc_index,\n",
    "                                       hpc['hidden_layer_sizes'],\n",
    "                                       hpc['learning_rate_init'],\n",
    "                                       hpc['batch_size'],\n",
    "                                       precision,\n",
    "                                       recall,\n",
    "                                       search_space_size\n",
    "                                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da380ec0-432a-4683-95ab-992cf0942f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpc_index</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>learning_rate_init</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>search_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>(100, 100, 100, 100)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.22</td>\n",
       "      <td>361858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>(100, 100, 100, 100)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.22</td>\n",
       "      <td>361423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(100, 100, 100)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.21</td>\n",
       "      <td>334170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.21</td>\n",
       "      <td>337987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.21</td>\n",
       "      <td>359068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>(200, 200, 200)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.19</td>\n",
       "      <td>363146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>(200, 200, 200)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.19</td>\n",
       "      <td>367077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>(100, 100, 100)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.20</td>\n",
       "      <td>367427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>(100, 100, 100, 100)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.20</td>\n",
       "      <td>357475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.19</td>\n",
       "      <td>358721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.17</td>\n",
       "      <td>340121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.18</td>\n",
       "      <td>330011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.18</td>\n",
       "      <td>334905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.17</td>\n",
       "      <td>353890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.19</td>\n",
       "      <td>339472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.17</td>\n",
       "      <td>350913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.16</td>\n",
       "      <td>281975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.17</td>\n",
       "      <td>332644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.16</td>\n",
       "      <td>356156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.16</td>\n",
       "      <td>349915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(100, 100, 100)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.260274</td>\n",
       "      <td>0.19</td>\n",
       "      <td>352451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(100, 100, 100)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.19</td>\n",
       "      <td>356228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.17</td>\n",
       "      <td>346892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>(100, 100, 100)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>352865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>(200, 200, 200)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.17</td>\n",
       "      <td>357606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.16</td>\n",
       "      <td>353395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.16</td>\n",
       "      <td>345844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.15</td>\n",
       "      <td>349833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>(200, 200, 200)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.14</td>\n",
       "      <td>356672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.14</td>\n",
       "      <td>336546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>(100, 100, 100, 100)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>340350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>(200, 200, 200)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.13</td>\n",
       "      <td>344783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>(100, 100, 100)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.13</td>\n",
       "      <td>315865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(200, 200, 200)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.13</td>\n",
       "      <td>338895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>(100, 100, 100, 100)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.06</td>\n",
       "      <td>340221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>(100, 100, 100, 100)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.02</td>\n",
       "      <td>342090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hpc_index    hidden_layer_sizes  learning_rate_init  batch_size  \\\n",
       "17         17  (100, 100, 100, 100)              0.0001         100   \n",
       "35         35  (100, 100, 100, 100)              0.0001         200   \n",
       "11         11       (100, 100, 100)              0.0001         100   \n",
       "8           8            (100, 100)              0.0001         100   \n",
       "26         26            (100, 100)              0.0001         200   \n",
       "14         14       (200, 200, 200)              0.0001         100   \n",
       "32         32       (200, 200, 200)              0.0001         200   \n",
       "29         29       (100, 100, 100)              0.0001         200   \n",
       "34         34  (100, 100, 100, 100)              0.0010         200   \n",
       "2           2              (50, 50)              0.0001         100   \n",
       "25         25            (100, 100)              0.0010         200   \n",
       "5           5          (50, 50, 50)              0.0001         100   \n",
       "1           1              (50, 50)              0.0010         100   \n",
       "20         20              (50, 50)              0.0001         200   \n",
       "6           6            (100, 100)              0.0100         100   \n",
       "23         23          (50, 50, 50)              0.0001         200   \n",
       "21         21          (50, 50, 50)              0.0100         200   \n",
       "24         24            (100, 100)              0.0100         200   \n",
       "7           7            (100, 100)              0.0010         100   \n",
       "19         19              (50, 50)              0.0010         200   \n",
       "9           9       (100, 100, 100)              0.0100         100   \n",
       "10         10       (100, 100, 100)              0.0010         100   \n",
       "18         18              (50, 50)              0.0100         200   \n",
       "28         28       (100, 100, 100)              0.0010         200   \n",
       "31         31       (200, 200, 200)              0.0010         200   \n",
       "0           0              (50, 50)              0.0100         100   \n",
       "22         22          (50, 50, 50)              0.0010         200   \n",
       "4           4          (50, 50, 50)              0.0010         100   \n",
       "13         13       (200, 200, 200)              0.0010         100   \n",
       "3           3          (50, 50, 50)              0.0100         100   \n",
       "16         16  (100, 100, 100, 100)              0.0010         100   \n",
       "30         30       (200, 200, 200)              0.0100         200   \n",
       "27         27       (100, 100, 100)              0.0100         200   \n",
       "12         12       (200, 200, 200)              0.0100         100   \n",
       "15         15  (100, 100, 100, 100)              0.0100         100   \n",
       "33         33  (100, 100, 100, 100)              0.0100         200   \n",
       "\n",
       "    precision  recall  search_space  \n",
       "17   0.379310    0.22        361858  \n",
       "35   0.372881    0.22        361423  \n",
       "11   0.368421    0.21        334170  \n",
       "8    0.362069    0.21        337987  \n",
       "26   0.355932    0.21        359068  \n",
       "14   0.345455    0.19        363146  \n",
       "32   0.339286    0.19        367077  \n",
       "29   0.338983    0.20        367427  \n",
       "34   0.322581    0.20        357475  \n",
       "2    0.322034    0.19        358721  \n",
       "25   0.298246    0.17        340121  \n",
       "5    0.290323    0.18        330011  \n",
       "1    0.285714    0.18        334905  \n",
       "20   0.283333    0.17        353890  \n",
       "6    0.275362    0.19        339472  \n",
       "23   0.269841    0.17        350913  \n",
       "21   0.266667    0.16        281975  \n",
       "24   0.265625    0.17        332644  \n",
       "7    0.262295    0.16        356156  \n",
       "19   0.262295    0.16        349915  \n",
       "9    0.260274    0.19        352451  \n",
       "10   0.256757    0.19        356228  \n",
       "18   0.253731    0.17        346892  \n",
       "28   0.250000    0.15        352865  \n",
       "31   0.250000    0.17        357606  \n",
       "0    0.242424    0.16        353395  \n",
       "22   0.228571    0.16        345844  \n",
       "4    0.214286    0.15        349833  \n",
       "13   0.212121    0.14        356672  \n",
       "3    0.202899    0.14        336546  \n",
       "16   0.200000    0.14        340350  \n",
       "30   0.191176    0.13        344783  \n",
       "27   0.173333    0.13        315865  \n",
       "12   0.166667    0.13        338895  \n",
       "15   0.071429    0.06        340221  \n",
       "33   0.022222    0.02        342090  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values('precision', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17cf0c12-fab2-4e6e-a8c0-613d14be0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('MLP_hyperparams_optimization.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
